{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.14.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "config_name='punjabi'\n",
        "\n",
        "dataset = load_dataset(\"csebuetnlp/xlsum\",config_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'url', 'title', 'summary', 'text'],\n",
              "        num_rows: 8215\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'url', 'title', 'summary', 'text'],\n",
              "        num_rows: 1026\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'url', 'title', 'summary', 'text'],\n",
              "        num_rows: 1026\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'international-45496712',\n",
              " 'url': 'https://www.bbc.com/punjabi/international-45496712',\n",
              " 'title': 'ਦੇਖਿਆ ਹੈ ਕਦੇ ਸਮੁੰਦਰ ਦਾ ਇਹ ਰੂਪ - ਤਸਵੀਰਾਂ',\n",
              " 'summary': \"ਬ੍ਰਿਟੇਨ ਵਿਚ ਇਸ ਸਾਲ ਸੇਲਰਜ਼ ਲਈ ਜਾਗਰੂਕਤਾ ਹਫ਼ਤਾ ਮਨਾਇਆ ਗਿਆ ਸੀ। ਇਸ ਦੌਰਾਨ ਬ੍ਰਿਟੇਨ ਦੀ ਸੰਸਥਾ 'ਸ਼ਿਪਰੇਕਡ ਮੈਰੀਨ ਸੁਸਾਇਟੀ' ਨੇ ਕੁਝ ਫੋਟੋਗ੍ਰਾਫ਼ਰਾਂ ਨੂੰ ਇਹ ਤਸਵੀਰਾਂ ਖਿੱਚਣ ਦੀ ਚੁਣੌਤੀ ਦਿੱਤੀ ਸੀ। ਉਸ ਮੁਕਾਬਲੇ ਵਿੱਚੋਂ ਹੀ ਇਹ ਕੁਝ ਤਸਵੀਰਾਂ ਚੁਣੀਆਂ ਗਈਆਂ ਹਨ।\",\n",
              " 'text': \"ਕ੍ਰਿਸ ਹੇਰਿੰਗ ਨੇ ਇਹ ਤਸਵੀਰ ਨੌਰਫਾਕ ਵਿਚ ਖਿੱਚੀ ਅਤੇ ਇਸ ਨੂੰ ਨਾਮ ਦਿੱਤਾ 'ਫਾਇਟਿੰਗ ਟੂ ਦਾ ਐਂਡ' ਮਤਲਬ ਆਖ਼ਰ ਤੱਕ ਸੰਘਰਸ਼ ਓਐੱਨ ਹਮਫੇਜ਼ ਨੇ ਡਰਹਮ ਦੇ ਲਾਇਟ ਹਾਊਸ ਦੇ ਨੇੜੇ ਉੱਠਦੀਆਂ ਲਹਿਰਾਂ ਦੇ ਜੋਸ਼ ਨੂੰ ਕੈਦ ਕੀਤਾ। ਓਐੱਨ ਹਮਫੇਜ਼ ਨੇ ਸਮੁੰਦਰ ਕੰਢੇ ਤੋਂ ਕਰੀਬ 48 ਕਿਲੋਮੀਟਰ ਦੂਰ ਇਹ ਤਸਵੀਰ ਖਿੱਚੀ। ਇਸ ਤਸਵੀਰ ਵਿਚ ਸੇਲਰ ਵਾਇਟਫਿਸ਼ ਫੜ੍ਹਨ ਦੀ ਤਿਆਰੀ ਕਰਦੇ ਦੇਖੇ ਜਾ ਸਕਦੇ ਹਨ। ਇਹ ਵੀ ਪੜ੍ਹੋ: ਟੇਰੀ ਪੇਨਜਿਲੇ ਨੇ ਇਸ ਤਸਵੀਰ ਵਿਚ 13 ਸਾਲ ਦੀ ਕੁੜੀ ਲੂਸੀ ਸਿਮਜ਼ ਨੂੰ ਕੈਦ ਕੀਤਾ ਸੀ। ਲੂਸੀ 6 ਕੁੜੀਆਂ ਦੀ ਉਸ ਰਿਲੇਅ ਟੀਮ ਦਾ ਹਿੱਸਾ ਸੀ, ਜਿਨ੍ਹਾਂ ਨੇ ਜੂਨ ਮਹੀਨੇ ਵਿਚ ਇੰਗਲਿਸ਼ ਚੈਨਲ ਪਾਰ ਕੀਤਾ ਸੀ। ਕਰੇਗ ਸਕੌਟ ਦੇ ਕੈਮਰੇ ਵਿਚ ਕੈਦ ਹੋਈ ਇਹ ਤਸਵੀਰ ਪਥਰੀਲੇ ਤਟ ਦਾ ਨਜ਼ਾਰਾ ਪੇਸ਼ ਕਰਦੀ ਹੈ। ਜੌਹਨ ਰੌਬਰਟਸ ਨੇ ਗਰੀਨ ਆਇਲ ਨਾਮ ਦੀ ਇਸ ਆਇਰਿਸ਼ ਬੇੜੀ ਦੀ ਤਸਵੀਰ ਤਰਕਾਲਾਂ ਵੇਲੇ ਖਿੱਚੀ ਸੀ ਇਹ ਤਸਵੀਰ ਡੇਵ ਏਜਲੀ ਨੇ ਲਈ ਹੈ। ਉਨ੍ਹਾਂ ਨੇ ਮੱਛੀਆਂ ਫੜ੍ਹਨ ਵਾਲੀ ਇੱਕ ਬੇੜੀ ਦੇ ਚਾਲਕ ਦਲ ਦੇ ਦੋ ਮੈਂਬਰਾਂ ਨੂੰ ਕੈਮਰੇ ਵਿਚ ਕੈਦ ਕੀਤਾ। ਇਹ ਤਸਵੀਰ ਇਆਨ ਰੀਡ ਦੇ ਕੈਮਰੇ ਰਾਹੀ ਸਾਹਮਣੇ ਆਈ। ਇਹ ਬੇੜੀ 1980 ਵਿਆਂ ਤੋਂ ਸਕਾਲੂਵਾ ਦੇ ਤਟ ਉੱਤੇ ਖੜ੍ਹੀ ਹੈ। ਤੁਹਾਨੂੰ ਇਹ ਵੀਡੀਓ ਵੀ ਪਸੰਦ ਆ ਸਕਦੇ ਹਨ- (ਬੀਬੀਸੀ ਪੰਜਾਬੀ ਨਾਲ FACEBOOK, INSTAGRAM, TWITTERਅਤੇ YouTube 'ਤੇ ਜੁੜੋ।)\"}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prefix = \"summarize: \"\n",
        "\n",
        "\n",
        "def preprocess_fn(examples):\n",
        "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
        "    text_target=[doc for doc in examples['summary']]\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "      labels = tokenizer(text_target, max_length=128, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6166e0e57e834cc187a43fc6d473f2c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1026 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenized_dataset = dataset.map(preprocess_fn, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'international-45496712',\n",
              " 'url': 'https://www.bbc.com/punjabi/international-45496712',\n",
              " 'title': 'ਦੇਖਿਆ ਹੈ ਕਦੇ ਸਮੁੰਦਰ ਦਾ ਇਹ ਰੂਪ - ਤਸਵੀਰਾਂ',\n",
              " 'summary': \"ਬ੍ਰਿਟੇਨ ਵਿਚ ਇਸ ਸਾਲ ਸੇਲਰਜ਼ ਲਈ ਜਾਗਰੂਕਤਾ ਹਫ਼ਤਾ ਮਨਾਇਆ ਗਿਆ ਸੀ। ਇਸ ਦੌਰਾਨ ਬ੍ਰਿਟੇਨ ਦੀ ਸੰਸਥਾ 'ਸ਼ਿਪਰੇਕਡ ਮੈਰੀਨ ਸੁਸਾਇਟੀ' ਨੇ ਕੁਝ ਫੋਟੋਗ੍ਰਾਫ਼ਰਾਂ ਨੂੰ ਇਹ ਤਸਵੀਰਾਂ ਖਿੱਚਣ ਦੀ ਚੁਣੌਤੀ ਦਿੱਤੀ ਸੀ। ਉਸ ਮੁਕਾਬਲੇ ਵਿੱਚੋਂ ਹੀ ਇਹ ਕੁਝ ਤਸਵੀਰਾਂ ਚੁਣੀਆਂ ਗਈਆਂ ਹਨ।\",\n",
              " 'text': \"ਕ੍ਰਿਸ ਹੇਰਿੰਗ ਨੇ ਇਹ ਤਸਵੀਰ ਨੌਰਫਾਕ ਵਿਚ ਖਿੱਚੀ ਅਤੇ ਇਸ ਨੂੰ ਨਾਮ ਦਿੱਤਾ 'ਫਾਇਟਿੰਗ ਟੂ ਦਾ ਐਂਡ' ਮਤਲਬ ਆਖ਼ਰ ਤੱਕ ਸੰਘਰਸ਼ ਓਐੱਨ ਹਮਫੇਜ਼ ਨੇ ਡਰਹਮ ਦੇ ਲਾਇਟ ਹਾਊਸ ਦੇ ਨੇੜੇ ਉੱਠਦੀਆਂ ਲਹਿਰਾਂ ਦੇ ਜੋਸ਼ ਨੂੰ ਕੈਦ ਕੀਤਾ। ਓਐੱਨ ਹਮਫੇਜ਼ ਨੇ ਸਮੁੰਦਰ ਕੰਢੇ ਤੋਂ ਕਰੀਬ 48 ਕਿਲੋਮੀਟਰ ਦੂਰ ਇਹ ਤਸਵੀਰ ਖਿੱਚੀ। ਇਸ ਤਸਵੀਰ ਵਿਚ ਸੇਲਰ ਵਾਇਟਫਿਸ਼ ਫੜ੍ਹਨ ਦੀ ਤਿਆਰੀ ਕਰਦੇ ਦੇਖੇ ਜਾ ਸਕਦੇ ਹਨ। ਇਹ ਵੀ ਪੜ੍ਹੋ: ਟੇਰੀ ਪੇਨਜਿਲੇ ਨੇ ਇਸ ਤਸਵੀਰ ਵਿਚ 13 ਸਾਲ ਦੀ ਕੁੜੀ ਲੂਸੀ ਸਿਮਜ਼ ਨੂੰ ਕੈਦ ਕੀਤਾ ਸੀ। ਲੂਸੀ 6 ਕੁੜੀਆਂ ਦੀ ਉਸ ਰਿਲੇਅ ਟੀਮ ਦਾ ਹਿੱਸਾ ਸੀ, ਜਿਨ੍ਹਾਂ ਨੇ ਜੂਨ ਮਹੀਨੇ ਵਿਚ ਇੰਗਲਿਸ਼ ਚੈਨਲ ਪਾਰ ਕੀਤਾ ਸੀ। ਕਰੇਗ ਸਕੌਟ ਦੇ ਕੈਮਰੇ ਵਿਚ ਕੈਦ ਹੋਈ ਇਹ ਤਸਵੀਰ ਪਥਰੀਲੇ ਤਟ ਦਾ ਨਜ਼ਾਰਾ ਪੇਸ਼ ਕਰਦੀ ਹੈ। ਜੌਹਨ ਰੌਬਰਟਸ ਨੇ ਗਰੀਨ ਆਇਲ ਨਾਮ ਦੀ ਇਸ ਆਇਰਿਸ਼ ਬੇੜੀ ਦੀ ਤਸਵੀਰ ਤਰਕਾਲਾਂ ਵੇਲੇ ਖਿੱਚੀ ਸੀ ਇਹ ਤਸਵੀਰ ਡੇਵ ਏਜਲੀ ਨੇ ਲਈ ਹੈ। ਉਨ੍ਹਾਂ ਨੇ ਮੱਛੀਆਂ ਫੜ੍ਹਨ ਵਾਲੀ ਇੱਕ ਬੇੜੀ ਦੇ ਚਾਲਕ ਦਲ ਦੇ ਦੋ ਮੈਂਬਰਾਂ ਨੂੰ ਕੈਮਰੇ ਵਿਚ ਕੈਦ ਕੀਤਾ। ਇਹ ਤਸਵੀਰ ਇਆਨ ਰੀਡ ਦੇ ਕੈਮਰੇ ਰਾਹੀ ਸਾਹਮਣੇ ਆਈ। ਇਹ ਬੇੜੀ 1980 ਵਿਆਂ ਤੋਂ ਸਕਾਲੂਵਾ ਦੇ ਤਟ ਉੱਤੇ ਖੜ੍ਹੀ ਹੈ। ਤੁਹਾਨੂੰ ਇਹ ਵੀਡੀਓ ਵੀ ਪਸੰਦ ਆ ਸਕਦੇ ਹਨ- (ਬੀਬੀਸੀ ਪੰਜਾਬੀ ਨਾਲ FACEBOOK, INSTAGRAM, TWITTERਅਤੇ YouTube 'ਤੇ ਜੁੜੋ।)\",\n",
              " 'input_ids': [21603,\n",
              "  10,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  31,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  31,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  4678,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  10,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  1179,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  431,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  6,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  6694,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  18,\n",
              "  41,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  377,\n",
              "  11539,\n",
              "  25793,\n",
              "  6,\n",
              "  3388,\n",
              "  4209,\n",
              "  26646,\n",
              "  4815,\n",
              "  6,\n",
              "  332,\n",
              "  518,\n",
              "  3177,\n",
              "  5946,\n",
              "  2,\n",
              "  5343,\n",
              "  3,\n",
              "  31,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  61,\n",
              "  1],\n",
              " 'attention_mask': [1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1],\n",
              " 'labels': [3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  31,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  31,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  1]}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "datacollator=DataCollatorForSeq2Seq(tokenizer=tokenizer,model=checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import create_optimizer, AdamWeightDecay\n",
        "\n",
        "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFAutoModelForSeq2SeqLM\n",
        "\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set = model.prepare_tf_dataset(\n",
        "    tokenized_dataset[\"train\"],\n",
        "    shuffle=True,\n",
        "    batch_size=8,\n",
        "    collate_fn=datacollator,\n",
        ")\n",
        "\n",
        "test_set = model.prepare_tf_dataset(\n",
        "    tokenized_dataset[\"test\"],\n",
        "    shuffle=False,\n",
        "    batch_size=8,\n",
        "    collate_fn=datacollator,\n",
        ")\n",
        "val_set = model.prepare_tf_dataset(\n",
        "    tokenized_dataset[\"validation\"],\n",
        "    shuffle=False,\n",
        "    batch_size=8,\n",
        "    collate_fn=datacollator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model.compile(optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EvaluationModule(name: \"rouge\", module_type: \"metric\", features: [{'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id=None)}, {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}], usage: \"\"\"\n",
              "Calculates average rouge scores for a list of hypotheses and references\n",
              "Args:\n",
              "    predictions: list of predictions to score. Each prediction\n",
              "        should be a string with tokens separated by spaces.\n",
              "    references: list of reference for each prediction. Each\n",
              "        reference should be a string with tokens separated by spaces.\n",
              "    rouge_types: A list of rouge types to calculate.\n",
              "        Valid names:\n",
              "        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n",
              "        `\"rougeL\"`: Longest common subsequence based scoring.\n",
              "        `\"rougeLsum\"`: rougeLsum splits text using `\"\n",
              "\"`.\n",
              "        See details in https://github.com/huggingface/datasets/issues/617\n",
              "    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n",
              "    use_aggregator: Return aggregates if this is set to True\n",
              "Returns:\n",
              "    rouge1: rouge_1 (f1),\n",
              "    rouge2: rouge_2 (f1),\n",
              "    rougeL: rouge_l (f1),\n",
              "    rougeLsum: rouge_lsum (f1)\n",
              "Examples:\n",
              "\n",
              "    >>> rouge = evaluate.load('rouge')\n",
              "    >>> predictions = [\"hello there\", \"general kenobi\"]\n",
              "    >>> references = [\"hello there\", \"general kenobi\"]\n",
              "    >>> results = rouge.compute(predictions=predictions, references=references)\n",
              "    >>> print(results)\n",
              "    {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
              "\"\"\", stored examples: 0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers.keras_callbacks import KerasMetricCallback\n",
        "\n",
        "callback=KerasMetricCallback(metric_fn=compute_metrics,eval_dataset=val_set,predict_with_generate=True,use_xla_generation=True,\n",
        "    generate_kwargs={\"max_length\": 128})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            " 487/1026 [=============>................] - ETA: 7:19:08 - loss: 0.2959"
          ]
        }
      ],
      "source": [
        "model.fit(train_set,validation_data=val_set,epochs=2,callbacks=callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "23b8c3b6c0d24af9b25c0da3ab1d28fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eb846faa76843c6b171c47f75c8bea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee7bac9c5a64489e97e50c320d745a50",
            "placeholder": "​",
            "style": "IPY_MODEL_bd8a6d7684284d12bbe18512966b6442",
            "value": "Map: 100%"
          }
        },
        "6166e0e57e834cc187a43fc6d473f2c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eb846faa76843c6b171c47f75c8bea8",
              "IPY_MODEL_6189c2701359480d9aaf8a79c8acfa72",
              "IPY_MODEL_69a91a5644354be19af36cefc79d71c8"
            ],
            "layout": "IPY_MODEL_a336420965e9493b81a7997d5bd576b7"
          }
        },
        "6189c2701359480d9aaf8a79c8acfa72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1342e58c85d49f6b7ecd13dfcb9276b",
            "max": 1026,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_867c8793c4d04b5cbb319b813873303a",
            "value": 1026
          }
        },
        "69a91a5644354be19af36cefc79d71c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23b8c3b6c0d24af9b25c0da3ab1d28fb",
            "placeholder": "​",
            "style": "IPY_MODEL_7ae480b70eec4d009d87b6fea322e021",
            "value": " 1026/1026 [00:04&lt;00:00, 206.83 examples/s]"
          }
        },
        "7ae480b70eec4d009d87b6fea322e021": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "867c8793c4d04b5cbb319b813873303a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a336420965e9493b81a7997d5bd576b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1342e58c85d49f6b7ecd13dfcb9276b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd8a6d7684284d12bbe18512966b6442": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee7bac9c5a64489e97e50c320d745a50": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
